import os
import torch
import torch.nn as nn
from fastapi import FastAPI
from pydantic import BaseModel
from transformers import BertJapaneseTokenizer, BertModel
import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv()

# --- Geminiè¨­å®š ---
GENAI_API_KEY = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=GENAI_API_KEY)
gemini_model = genai.GenerativeModel('gemini-1.5-flash')

# --- BERTãƒ¢ãƒ‡ãƒ«å®šç¾© ---
MODEL_NAME = 'cl-tohoku/bert-base-japanese-v3'

class FraudDetector(nn.Module):
    def __init__(self, n_meta_features):
        super(FraudDetector, self).__init__()
        self.bert = BertModel.from_pretrained(MODEL_NAME)
        self.drop = nn.Dropout(p=0.3)
        self.meta_layer = nn.Linear(n_meta_features, 32)
        self.out = nn.Linear(768 + 32, 1)

    def forward(self, input_ids, attention_mask, metadata):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        bert_out = self.drop(outputs.pooler_output)
        meta_out = torch.relu(self.meta_layer(metadata))
        combined = torch.cat((bert_out, meta_out), dim=1)
        return self.out(combined)

# --- ã‚µãƒ¼ãƒãƒ¼èµ·å‹•æ™‚ã®æº–å‚™ ---
app = FastAPI()
device = torch.device("cpu") # Cloud Runã¯CPU
tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)

# â˜…â˜…â˜… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰éƒ¨åˆ†ã®ä¿®æ­£ (é‡å­åŒ–å¯¾å¿œ) â˜…â˜…â˜…
print("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
n_perms = 4 
model = FraudDetector(n_meta_features=n_perms)

# é‡è¦: é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€Œå‰ã€ã«ã€ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã‚’é‡å­åŒ–ãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›ã™ã‚‹
# ã“ã‚Œã‚’è¡Œã‚ãªã„ã¨ã€ä¿å­˜ã•ã‚ŒãŸint8ã®é‡ã¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“
model = torch.quantization.quantize_dynamic(
    model, 
    {torch.nn.Linear},  # BERTã®Linearå±¤ã‚’å¯¾è±¡ã«ã™ã‚‹
    dtype=torch.qint8
)

# é‡å­åŒ–ã•ã‚ŒãŸé‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
model_path = "fraud_model_quantized.pth"

if os.path.exists(model_path):
    print(f"ğŸ“‚ è»½é‡åŒ–ãƒ¢ãƒ‡ãƒ« {model_path} ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...")
    try:
        model.load_state_dict(torch.load(model_path, map_location=device))
        print("âœ… ãƒ­ãƒ¼ãƒ‰æˆåŠŸï¼ãƒ¡ãƒ¢ãƒªç¯€ç´„ãƒ¢ãƒ¼ãƒ‰ã§ç¨¼åƒã—ã¾ã™ã€‚")
    except Exception as e:
        print(f"âŒ ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        print("   train_model.py ã§æ­£ã—ãé‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
else:
    print(f"âš ï¸ {model_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼")
    print("   å…ˆã« train_model.py ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")

model.eval()

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å½¢å¼
class AppInfo(BaseModel):
    description: str
    permissions: list

# --- åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ ---
async def call_gemini_analysis(text, perms):
    prompt = f"""
    ã‚ãªãŸã¯Androidã‚¢ãƒ—ãƒªã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å°‚é–€å®¶ã§ã™ã€‚
    ä»¥ä¸‹ã®ã‚¢ãƒ—ãƒªæƒ…å ±ãŒã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’é¨™ã™è©æ¬ºã‚¢ãƒ—ãƒªã€ã‹ã©ã†ã‹ã‚’åˆ¤å®šã—ã€
    ç†ç”±ã¨ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ï¼ˆ0-1.0ï¼‰ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

    ã€ã‚¢ãƒ—ãƒªèª¬æ˜æ–‡ã€‘: {text}
    ã€è¦æ±‚ã•ã‚Œã¦ã„ã‚‹æ¨©é™ã€‘: {', '.join(perms)}

    å‡ºåŠ›å½¢å¼ã¯å¿…ãšä»¥ä¸‹ã®JSONã«ã—ã¦ãã ã•ã„ï¼ˆMarkdownãªã©ã®è£…é£¾ã¯ä¸è¦ã§ã™ï¼‰:
    {{"risk_score": 0.8, "reason": "ã“ã“ã«çŸ­ã„ç†ç”±"}}
    """
    try:
        response = gemini_model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f'{{"risk_score": 0.5, "reason": "Gemini API Error: {str(e)}"}}'

@app.post("/predict")
async def predict(info: AppInfo):
    # 1. BERTã«ã‚ˆã‚‹1æ¬¡åˆ¤å®š
    risky_perms = ["SYSTEM_ALERT_WINDOW", "RECEIVE_BOOT_COMPLETED", "BIND_ACCESSIBILITY_SERVICE", "READ_CONTACTS"]
    perm_vec = [1.0 if p in info.permissions else 0.0 for p in risky_perms]
    
    encoding = tokenizer(
        info.description,
        max_length=128,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    )

    with torch.no_grad():
        output = model(
            input_ids=encoding['input_ids'],
            attention_mask=encoding['attention_mask'],
            metadata=torch.tensor([perm_vec], dtype=torch.float)
        )
        bert_score = torch.sigmoid(output).item()

    # 2. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ¤å®š
    # ã‚¹ã‚³ã‚¢ãŒ 0.45 ~ 0.55 ã®å¾®å¦™ãªãƒ©ã‚¤ãƒ³ã®å ´åˆã®ã¿ Gemini ã«èã
    if 0.45 <= bert_score <= 0.55:
        print(f"ğŸ¤” BERTè¿·ã„ä¸­(Score: {bert_score:.4f})... Geminiã«ç›¸è«‡ã—ã¾ã™ã€‚")
        gemini_result = await call_gemini_analysis(info.description, info.permissions)
        return {
            "method": "Gemini (Hybrid)",
            "bert_raw_score": bert_score,
            "gemini_analysis": gemini_result
        }
    else:
        # BERTã§å³æ±º
        print(f"âš¡ BERTå³æ±º(Score: {bert_score:.4f})")
        return {
            "method": "BERT (Fast)",
            "score": bert_score,
            "is_fraud": bert_score > 0.5
        }