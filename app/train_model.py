import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import BertJapaneseTokenizer, BertModel
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score
import gc
from tqdm import tqdm
import os  # â˜…è¿½åŠ : ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèªç”¨

# --- è¨­å®š ---
BATCH_SIZE = 8       
EPOCHS = 3            
LEARNING_RATE = 2e-5  
MAX_LEN = 128         
MODEL_NAME = 'cl-tohoku/bert-base-japanese-v3'

# --- ãƒ‡ãƒã‚¤ã‚¹ã®è‡ªå‹•é¸æŠ ---
def get_device():
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name(0)
        print(f"ğŸš€ GPUãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {device_name}")
        return torch.device("cuda")
    else:
        print("âš ï¸ GPUãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚CPUã§å­¦ç¿’ã—ã¾ã™ï¼ˆæ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰ã€‚")
        return torch.device("cpu")

DEVICE = get_device()

# --- 1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®šç¾© ---
class AppDataset(Dataset):
    def __init__(self, df, tokenizer, max_len):
        self.df = df
        self.tokenizer = tokenizer
        self.max_len = max_len
        self.risky_perms = [
            "SYSTEM_ALERT_WINDOW", "RECEIVE_BOOT_COMPLETED", 
            "BIND_ACCESSIBILITY_SERVICE", "READ_CONTACTS"
        ]

    def __len__(self):
        return len(self.df)

    def __getitem__(self, index):
        row = self.df.iloc[index]
        text = str(row['description']) if pd.notna(row['description']) else ""
        perms_str = str(row['permissions']) if pd.notna(row['permissions']) else ""
        perm_vec = [1.0 if rp in perms_str else 0.0 for rp in self.risky_perms]
        
        encoding = self.tokenizer(
            text,
            add_special_tokens=True,
            max_length=self.max_len,
            return_token_type_ids=False,
            padding='max_length',
            truncation=True,
            return_attention_mask=True,
            return_tensors='pt',
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'metadata': torch.tensor(perm_vec, dtype=torch.float),
            'labels': torch.tensor(row['is_fraud'], dtype=torch.float)
        }

# --- 2. ãƒ¢ãƒ‡ãƒ«å®šç¾© (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å‹) ---
class FraudDetector(nn.Module):
    def __init__(self, n_meta_features):
        super(FraudDetector, self).__init__()
        self.bert = BertModel.from_pretrained(MODEL_NAME)
        self.drop = nn.Dropout(p=0.3)
        self.meta_layer = nn.Linear(n_meta_features, 32)
        self.out = nn.Linear(768 + 32, 1)

    def forward(self, input_ids, attention_mask, metadata):
        outputs = self.bert(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        bert_out = self.drop(outputs.pooler_output)
        meta_out = torch.relu(self.meta_layer(metadata))
        combined = torch.cat((bert_out, meta_out), dim=1)
        return self.out(combined)

# --- 3. å­¦ç¿’ãƒ«ãƒ¼ãƒ—é–¢æ•° ---
def train_epoch(model, data_loader, loss_fn, optimizer, scheduler, n_examples):
    model = model.train()
    losses = []
    correct_predictions = 0
    scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())

    for d in tqdm(data_loader, desc="Training"):
        input_ids = d["input_ids"].to(DEVICE)
        attention_mask = d["attention_mask"].to(DEVICE)
        metadata = d["metadata"].to(DEVICE)
        labels = d["labels"].to(DEVICE)

        optimizer.zero_grad()

        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                metadata=metadata
            )
            loss = loss_fn(outputs, labels.unsqueeze(1))

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        if scheduler:
            scheduler.step()

        preds = torch.sigmoid(outputs).round()
        correct_predictions += torch.sum(preds.flatten() == labels)
        losses.append(loss.item())
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    return correct_predictions.double() / n_examples, np.mean(losses)

# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ---
def main():
    try:
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
        # ãƒ‘ã‚¹ã¯ç’°å¢ƒã«åˆã‚ã›ã¦é©å®œä¿®æ­£ã—ã¦ãã ã•ã„
        if os.path.exists(r'C:\learn\scamwall\app_dataset_labeled.csv'):
            csv_path = r'C:\learn\scamwall\app_dataset_labeled.csv'
        else:
            csv_path = 'app_dataset_labeled.csv' # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç”¨
            
        df = pd.read_csv(csv_path)
        
        if len(df) < 10:
            print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã¾ã™ã€‚")
            return

        df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)
        tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)
        
        train_dataset = AppDataset(df_train, tokenizer, MAX_LEN)
        test_dataset = AppDataset(df_test, tokenizer, MAX_LEN)
        
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)

        model = FraudDetector(n_meta_features=4) 
        model = model.to(DEVICE)

        optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)
        loss_fn = nn.BCEWithLogitsLoss().to(DEVICE)

        print("ğŸ”¥ å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
        
        for epoch in range(EPOCHS):
            print(f'Epoch {epoch + 1}/{EPOCHS}')
            print('-' * 10)

            try:
                train_acc, train_loss = train_epoch(
                    model, train_loader, loss_fn, optimizer, None, len(df_train)
                )
                print(f'Train loss {train_loss} accuracy {train_acc}')
                
            except RuntimeError as e:
                if 'out of memory' in str(e):
                    print("âŒ GPUãƒ¡ãƒ¢ãƒªä¸è¶³ï¼BATCH_SIZEã‚’ä¸‹ã’ã¦ãã ã•ã„ã€‚")
                    break
                else:
                    raise e

        # 1. é€šå¸¸ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        print("âœ… å­¦ç¿’å®Œäº†ã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã™ã€‚")
        torch.save(model.state_dict(), 'fraud_model.pth')
        
        # --- â˜…ã“ã“ã‹ã‚‰é‡å­åŒ–å‡¦ç† (Cloud Run 2GBåˆ¶é™å¯¾å¿œ) ---
        print("\nğŸ“‰ ãƒ¢ãƒ‡ãƒ«ã‚’é‡å­åŒ–ï¼ˆè»½é‡åŒ–ï¼‰ã—ã¦ã„ã¾ã™...")
        
        # é‡å­åŒ–ã¯CPUä¸Šã§è¡Œã†å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã‚’CPUã¸ç§»å‹•
        model.to('cpu')
        model.eval()

        # å‹•çš„é‡å­åŒ–ã®é©ç”¨ (Linearå±¤ã‚’int8ã«å¤‰æ›)
        # BERTã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã¯Linearå±¤ãªã®ã§ã€åŠ‡çš„ã«è»½ããªã‚Šã¾ã™
        quantized_model = torch.quantization.quantize_dynamic(
            model, 
            {torch.nn.Linear},  # å¯¾è±¡ã¨ã™ã‚‹å±¤
            dtype=torch.qint8
        )

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¯”è¼ƒç”¨ã®å‡ºåŠ›
        org_size = os.path.getsize('fraud_model.pth') / 1024 / 1024
        print(f"ğŸ“¦ ã‚ªãƒªã‚¸ãƒŠãƒ«ã‚µã‚¤ã‚º: {org_size:.2f} MB")

        # é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        torch.save(quantized_model.state_dict(), 'fraud_model_quantized.pth')
        
        q_size = os.path.getsize('fraud_model_quantized.pth') / 1024 / 1024
        print(f"ğŸ’¾ é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: fraud_model_quantized.pth ({q_size:.2f} MB)")
        print(f"ğŸš€ åœ§ç¸®ç‡: {q_size/org_size*100:.1f}% (Cloud Runç„¡æ–™æ ã§å‹•ä½œå¯èƒ½ã§ã™)")

    except FileNotFoundError:
        print("ã‚¨ãƒ©ãƒ¼: app_dataset_labeled.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

if __name__ == "__main__":
    main()